---
layout: post
title: My journey with Azure DocumentDb
date: '2016-11-15T15:36:00.001Z'
author: Frans Lytzen
tags: 
modified_time: '2016-11-15T15:36:06.545Z'
blogger_id: tag:blogger.com,1999:blog-8302357413081836531.post-2556839986716353096
blogger_orig_url: http://blog.lytzen.name/2016/11/my-journey-with-azure-documentdb.html
---

I have recently been using Azure DocumentDb on two separate projects. It has very much been a journey of discovery and, while there have been some bumps in the road, I have ended up in a place where I am very happy with DocumentDb; When used in the way it is meant to be used, it is extremely fast, to the point where I can get documents in sub 10ms from a database with over 6 million documents.<br /><div><br /></div><div><b>TL;DR; </b>When used correctly, DocumentDb is ridiculously fast. Like most document databases it also makes development simpler by not making you worry about schemas, though the usual caveats apply. It's also managed by Azure, which means you don't have to worry about maintaining infrastructure, looking after servers, uptime and all that - a factor that is often overlooked but has significant agility and cost implications down the line.</div><div>On the down side, there is no concept of linking documents or anything like RavenDB's "indexes", which are more like materialised views (an incredibly awesome feature that would add a lot of value to DocumentDb). I think it's also fair to say that DocumentDb is still quite young and it's missing stuff, some of the tooling is immature and so on. That said, the team is iterating rapidly and are releasing new versions and features at a frightening rate.</div><div><br /></div><div><br />It hasn't been a completely smooth journey and I wanted to write this post to share some of what I found. The biggest challenge really is that you need to think in a very different way about your data structures, which takes some trial and error. DocumentDb forces you to make explicit decisions about scaling in your design; you can't just leave it to DocumentDb to scale for you, as you might with some other databases. I personally happen to think this is ultimately a good thing, but it does very much depend on your particular usecase - sometimes it's easier to just pay the money for a very beefy SQL Server and lots of memory.<br /><h2>Thinking about your data structure</h2></div><div>If you are ever going to store more than 10gb in your document Db, you will need to think quite carefully about how you structure your data; you <i>can</i> choose to ignore it and let DocumentDb handle it for you and you'll get okay performance, although probably at a noticeably higher cost.</div><div><br /></div><div><b>This is a good thing</b>. Too often are developers seduced by the idea that a given database will do all the scaling for them - until it doesn't or it becomes cost prohibitive. Fixing it at that point tends to be a lot harder. That said, some problem sets just aren't suited to the way you have to use DocumentDb - always look at the problem at hand and use the correct solution or even a combination.<br /><br /></div><div>I intend to write a more detailed post about how to structure DocumentDb partitions and collections - it is too big a subject for this post.</div><div><h2>Information Security (InfoSec)</h2></div><div>SQL Azure has come a long way in the last several years and now has <a href="http://blog.lytzen.name/2016/08/infosec-with-sql-azure.html">excellent InfoSec compliance</a>. DocumentDb - not so much. Understand me right; the way Azure actually works means that DocumentDb is probably a lot more secure than most database you host yourselves and from a technical security point of view, I have absolutely no concerns. However, InfoSec people tend to insist on things like "encryption at rest" (which is nonsense in Azure, but you try explaining that to an auditor with a spreadsheet), auditing of user access (which is actually sensible) and so on and so forth. DocumentDb hasn't really got those things yet, though I'm sure it's only a matter of time.</div><h2>Request Units - predictable performance</h2><div>DocumentDb prides itself on having very predictable performance by letting you scale up seamlessly in terms of "request units". The API returns information about how many RUs each call costs you and when you are using too much you get an appropriate "retry in x time" message back etc. This is extremely useful and I have taken to building logging in to the front-end app to identify expensive queries etc; Literally every database query is logged in <a href="https://getseq.net/">Seq</a> along with information about who the user was, what the request context was and exactly how many RUs the request consumed. This makes it very easy to search for expensive queries and, knowing the context, makes it feasible to fix the problem. Compare this to SQL where you have to find the query in SQL Profiler or Azure's SQL Query Store then try to correlate it to what happened on the front-end.&nbsp;</div><div><br /></div><div><br /></div><div><h2><br /></h2><div><br /></div><div><br /></div><div>Size - bigger than SQL.</div><div><br /></div><div>Info sec</div><div>Languages</div><div>Nugget gripe</div><div>Global scale</div><div>Powerful projection and flattening options#<br />PowerBI integration<br />Triggers and stored procedures</div><div><br /></div><br /></div>